{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",                                //importing pandas for converting raw data into dataframes
    "import os\n",                                          // this lib is for using kernal operations 
    "import numpy as np\n",                                 // numerical pyhton for operation on matrix
    "from sklearn import preprocessing,cross_validation, neighbors\n",   //
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from __future__ import division\n",
    "import string\n",
    "import math\n",
    "tokenize = lambda doc: doc.lower().split(\" \")\n",
    "import re\n",
    "from bs4.element import Comment\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.svm import LinearSVC\n",
    " \n",
    "\n",
    "tokenize = lambda doc: doc.lower().split(\" \")\n",
    "\n",
    "\n",
    "\n",
    "HOUSING_PATH = \"C:/Users/yogeshmaurya/Desktop/proj/benchmark_pheme\"\n",  //providing dataset path 
    "def load_sample_data(housing_path=HOUSING_PATH): \n",                      // function to read dataset from csv file
    "    os.chdir(housing_path) \n",                                            // change directory
    "    return pd.read_csv(\"sydneysiege.csv\")\n",                            // reading .csv file
    "\n",
    "\n",
    "# In[264]:\n",
    "\n",
    "\n",
    "sample = load_sample_data()\n",                                          // function calling to load dataset
    "\n",
    // sample.drop() will delete the row/col from dataframe ;inplace to True changes the original DataFrame //
    "sample.drop('contributors',axis=1,inplace=True)\n",
    "sample.drop('truncated',axis=1,inplace=True)\n",
    "#sample.drop('text',axis=1,inplace=True)\n",
    "sample.drop('description',axis=1,inplace=True)\n",
    "sample.drop('profile_use_background_image',axis=1,inplace=True)\n",
    "sample.drop('default_profile',axis=1,inplace=True)\n",
    "sample.drop('following',axis=1,inplace=True)\n",
    "sample.drop('geo_enabled',axis=1,inplace=True)\n",
    "\n",
    "\n",
    "sample.drop('created_at',axis=1,inplace=True)\n",
    "sample.drop('in_reply_to_status_id_str',axis=1,inplace=True)\n",
    "\n",
    "sample.drop('in_reply_to_status_id',axis=1,inplace=True)\n",
    "sample.drop('retweeted',axis=1,inplace=True)\n",
    "sample.drop('coordinates',axis=1,inplace=True)\n",
    "sample.drop('source',axis=1,inplace=True)\n",
    "sample.drop('in_reply_to_screen_name',axis=1,inplace=True)\n",
    "sample.drop('id_str',axis=1,inplace=True)\n",
    "sample.drop('favorited',axis=1,inplace=True)\n",
    "sample.drop('geo',axis=1,inplace=True)\n",
    "sample.drop('in_reply_to_user_id_str',axis=1,inplace=True)\n",
    "sample.drop('lang',axis=1,inplace=True)\n",
    "sample.drop('place',axis=1,inplace=True)\n",
    "sample.drop('contributors_enabled',axis=1,inplace=True)\n",
    "sample.drop('user_created_at',axis=1,inplace=True)\n",
    "sample.drop('default_profile_image',axis=1,inplace=True)\n",
    "\n",
    "#sample.drop('description',axis=1,inplace=True)\n",
    "\n",
    "sample.drop('follow_request_sent',axis=1,inplace=True)\n",
    "\n",
    "\n",
    "sample.drop('location',axis=1,inplace=True)\n",
    "sample.drop('entities_hashtags',axis=1,inplace=True)\n",
    "sample.drop('id_protectedstr',axis=1,inplace=True)\n",
    "sample.drop('screen_name',axis=1,inplace=True)\n",
    "sample.drop('name',axis=1,inplace=True)\n",
    "sample.drop('notifications',axis=1,inplace=True)\n",
    "sample.drop('time_zone',axis=1,inplace=True)\n",
    "sample.drop('utc_offset',axis=1,inplace=True)\n",
    "\n",
    "sample.drop('id',axis=1,inplace=True)\n",
    "\n",
    "sample.drop('in_reply_to_user_id',axis=1,inplace=True)\n",
    "\n",
    "sample.drop('profile_text_color',axis=1,inplace=True)\n",
    "\n",
    "sample.drop('entities_symbols',axis=1,inplace=True)\n",
    "\n",
    "sample.drop('entities_user_mentions',axis=1,inplace=True)\n",
    "\n",
    "sample.drop('entities_urls',axis=1,inplace=True)\n",
    "\n",
    "sample.drop('user_idstr',axis=1,inplace=True)\n",
    "sample.drop('profile_link_color',axis=1,inplace=True)\n",
    "sample.drop('profile_image_url',axis=1,inplace=True)\n",
    "sample.drop('profile_background_tile',axis=1,inplace=True)\n",
    "sample.drop('profile_background_color',axis=1,inplace=True)\n",
    "sample.drop('profile_background_image_url',axis=1,inplace=True)\n",
    "sample.drop('profile_background_image_url_https',axis=1,inplace=True)\n",
    "sample.drop('profile_image_url_https',axis=1,inplace=True)\n",
    "\n",
    "sample.drop('user_id',axis=1,inplace=True)\n",
    "sample.drop('profile_sidebar_fill_color',axis=1,inplace=True)\n",
    "sample.drop('profile_sidebar_border_color',axis=1,inplace=True)\n",
    "#sample.drop('possibly_sensitive',axis=1,inplace=True)\n",
    "#sample.drop('is_translation_enabled',axis=1,inplace=True)\n",
    "\n",
    "\n",
    "def term_frequency(term, tokenized_document):\n",
    "    return tokenized_document.count(term)\n",
    "\n",
    "def sublinear_term_frequency(term, tokenized_document):\n",
    "    count = tokenized_document.count(term)\n",
    "    if count == 0:\n",
    "        return 0\n",
    "    return 1 + math.log(count)\n",
    "\n",
    "def augmented_term_frequency(term, tokenized_document):\n",
    "    max_count = max([term_frequency(t, tokenized_document) for t in tokenized_document])\n",
    "    return (0.5 + ((0.5 * term_frequency(term, tokenized_document))/max_count))\n",
    "\n",
    "def inverse_document_frequencies(tokenized_documents):\n",
    "    idf_values = {}\n",
    "    all_tokens_set = set([item for sublist in tokenized_documents for item in sublist])\n",
    "    for tkn in all_tokens_set:\n",
    "        contains_token = map(lambda doc: tkn in doc, tokenized_documents)\n",
    "        idf_values[tkn] = 1 + math.log(len(tokenized_documents)/(sum(contains_token)))\n",
    "    return idf_values\n",
    "\n",
    
    "\n",
    // creating list of all the labeles inside dataset e.g text , description
    "words=list(sample['text'])\n",
    "\n",
    "#words2=list(sample['description'])\n",
    "\n",
    "\n",
    "def tfidf(documents):\n",
    "    tokenized_documents = [tokenize(d) for d in documents]\n",
    "    idf = inverse_document_frequencies(tokenized_documents)\n",
    "    tfidf_documents = []\n",
    "    for document in tokenized_documents:\n",
    "        doc_tfidf = []\n",
    "        for term in idf.keys():\n",
    "            tf = sublinear_term_frequency(term, document)\n",
    "            doc_tfidf.append(tf * idf[term])\n",
    "        tfidf_documents.append(doc_tfidf)\n",
    "    return tfidf_documents\n",
    "\n",
    "#rint(words)\n",
    "#words = (list([mails['label'] == 0]['message']))\n",
    "\n",
    "\n",
    "tfi = tfidf(words)\n",
    "#tf2=  tfidf(words2)\n",
    "\n",
    "\n",
    "def sumx(vector1):\n",
    "    s=sum(p for p in (vector1))\n",
    "    return s\n",
    "j=0\n",
    "\n",
    "\n",
    "for i in tfi:\n",
    "    t=sumx(i)\n",
    "    \n",
    "    sample.iat[j,0]=t\n",
    "    j=j+1\n",
    "j=0\n",
    "\n",
    "\"\"\"for i in tf2:\n",
    "    t=sumx(i)\n",
    "    \n",
    "    sample.iat[j,4]=t\n",
    "    j=j+1\n",
    "\"\"\"\n",
    "   \n",
    "\n",
    "sample['text']=sample.text.astype(int)\n",
    "#sample['description']=sample.description.astype(int)\n",
    "\n",
    "\n",
    "\n",
    "sample.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.ufunc size changed, may indicate binary incompatibility. Expected 216 from C header, got 192 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a0e13cd46f84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneural_network\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_IS_32BIT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m _DEFAULT_TAGS = {\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmurmurhash\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmurmurhash3_32\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_joblib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m__init__.pxd\u001b[0m in \u001b[0;36minit sklearn.utils.murmurhash\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216 from C header, got 192 from PyObject"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x=np.array(sample.drop(['class'],1))\n",
    "y=np.array(sample['class'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test= cross_validation.train_test_split(x,y,test_size=0.18)\n",
    "\n",
    "clf=neighbors.KNeighborsClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(\"KNN\\n\")\n",
    "print(\"accuracy\")\n",
    "print(clf.score(x_test,y_test))\n",
    "#print(\"\\n\")\n",
    "print(\"f1_score \")\n",
    "print(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "#print(\"\\n\")\n",
    "print(\"precision \")\n",
    "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "#print(\"\\n\")\n",
    "print(\"recall \")\n",
    "print(recall_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nclf=MLPClassifier(solver=\"lbfgs\",alpha=1e-5,hidden_layer_sizes=(100,80,30,10,1))\n",
    "nclf.fit(x_train,y_train)\n",
    "y_pred0 = nclf.predict(x_test)\n",
    "\n",
    "print(\"MLP\\n\")\n",
    "print(\"accuracy\")\n",
    "print(clf.score(x_test,y_test))\n",
    "#print(\"\\n\")\n",
    "print(\"accuracy\")\n",
    "print(nclf.score(x_test,y_test))\n",
    "#print(\"\\n\")\n",
    "print(\"f1_score \")\n",
    "print(f1_score(y_test, y_pred0, average=\"macro\"))\n",
    "#print(\"\\n\")\n",
    "print(\"precision\")\n",
    "print(precision_score(y_test, y_pred0, average=\"macro\"))\n",
    "#print(\"\\n\")\n",
    "print(\"recall\")\n",
    "print(recall_score(y_test, y_pred0, average=\"macro\"))\n",
    "#print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=41, oob_score=True, random_state=156)\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred2 = rf.predict(x_test)\n",
    "print(\"random forest\\n\")\n",
    "print(\"accuracy\")\n",
    "print(rf.score(x_test,y_test))\n",
    "#print(\"\\n\")\n",
    "print(\"f1_score\")\n",
    "print(f1_score(y_test, y_pred2, average=\"macro\"))\n",
    "#print(\"\\n\")\n",
    "print(\"precision\")\n",
    "print(precision_score(y_test, y_pred2, average=\"macro\"))\n",
    "#print(\"\\n\")\n",
    "print(\"recall\")\n",
    "print(recall_score(y_test, y_pred2, average=\"macro\"))\n",
    "#print(\"\\n\")\n",
    "\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=60, max_iter=800) # if you want reproducible results set the random_state value.\n",
    "sgd_clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred3 = sgd_clf.predict(x_test)\n",
    "print(\"sgd classifier\\n\")\n",
    "print(\"accuracy\")\n",
    "print(sgd_clf.score(x_test,y_test))\n",
    "#print(\"\\n\")\n",
    "print(\"f1_score\")\n",
    "print(f1_score(y_test, y_pred3, average=\"macro\"))\n",
    "#print(\"\\n\")\n",
    "print(\"precision\")\n",
    "print(precision_score(y_test, y_pred3, average=\"macro\"))\n",
    "\n",
    "#print(\"\\n\")\n",
    "print(\"recall\")\n",
    "print(recall_score(y_test, y_pred3, average=\"macro\")) \n",
    "#print(\"\\n\")\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "bnb = BernoulliNB(binarize=0.70)\n",
    "bnb.fit(x_train, y_train)\n",
    "y_pred4 = bnb.predict(x_test)\n",
    "\n",
    "print(\"naive baiyes\\n\")\n",
    "print(\"accuracy\")\n",
    "print(bnb.score(x_test,y_test))\n",
    "#print(\"\\n\")\n",
    "\n",
    "print(f1_score(y_test, y_pred4, average=\"macro\"))\n",
    "print(precision_score(y_test, y_pred4, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred4, average=\"macro\")) \n",
    "#print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# In[212]:\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(x_train, y_train)\n",
    "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "mnb.score(x_test,y_test)\n",
    "\n",
    "print(\"multinomial nb \\n\")\n",
    "print(\"accuracy\")\n",
    "print(mnb.score(x_test,y_test))\n",
    "print(\"\\n\")\n",
    "y_pred5 = mnb.predict(x_test)\n",
    "print(f1_score(y_test, y_pred5, average=\"macro\"))\n",
    "print(precision_score(y_test, y_pred5, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred5, average=\"macro\"))  \n",
    "\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svm=SVC(kernel=\"linear\",C=0.025,random_state=101)\n",
    "svm.fit(x_train,y_train)\n",
    "y_pred6=svm.predict(x_test)\n",
    "print(\"svm \\n\")\n",
    "print(\"accuracy\")\n",
    "print(svm.score(x_test,y_test))\n",
    "print(\"\\n\")\n",
    "print(svm.score(x_test,y_test))\n",
    "print(f1_score(y_test, y_pred6, average=\"macro\"))\n",
    "print(precision_score(y_test, y_pred6, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred6, average=\"macro\"))  \n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "y_pred7=lr.predict(x_test)\n",
    "print(\"logistic regression \\n\")\n",
    "print(\"accuracy\")\n",
    "print(mnb.score(x_test,y_test))\n",
    "print(\"\\n\")\n",
    "print(lr.score(x_test,y_test))\n",
    "print(f1_score(y_test, y_pred7, average=\"macro\"))\n",
    "print(precision_score(y_test, y_pred7, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred7, average=\"macro\"))  \n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree=DecisionTreeClassifier(max_depth=10,random_state=101, max_features=None, min_samples_leaf=15)\n",
    "dtree.fit(x_train,y_train)\n",
    "y_pred=dtree.predict(x_test)\n",
    "print(\"decision tree \\n\")\n",
    "print(\"accuracy\")\n",
    "print(dtree.score(x_test,y_test))\n",
    "print(\"\\n\")\n",
    "print(dtree.score(x_test,y_test))\n",
    "print(f1_score(y_test, y_pred7, average=\"macro\"))\n",
    "print(precision_score(y_test, y_pred7, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred7, average=\"macro\"))\n",
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
